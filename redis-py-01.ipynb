{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2-i8jBl9GRH"
      },
      "source": [
        "![Redis](https://redis.com/wp-content/themes/wpx/assets/images/logo-redis.svg?auto=webp&quality=85,75&width=120)\n",
        "\n",
        "# Introduction to Redis Python\n",
        "\n",
        "This notebook introduces [Redis](https://redis.io) and the standard Python client, [redis-py](https://redis-py.readthedocs.io/en/stable/), for interacting with the database. We will explore the basics of Redis setup, data structures, and capabilities like vector search!\n",
        "\n",
        "## Let's Begin!\n",
        "<a href=\"https://colab.research.google.com/github/redis-developer/financial-vss/blob/main/redis-py-01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UG2-tksuPpl"
      },
      "source": [
        "## Environment Setup\n",
        "\n",
        "### Pull Github Materials\n",
        "Because you are likely running this notebook in **Google Colab**, we need to first\n",
        "pull the necessary dataset and materials directly from GitHub.\n",
        "\n",
        "**If you are running this notebook locally**, FYI you may not need to perform this\n",
        "step at all."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BA3TXPWTuPpo"
      },
      "outputs": [],
      "source": [
        "# This clones the supporting git repository into a directory named 'temp_repo'.\n",
        "!git clone https://github.com/redis-developer/financial-vss.git temp_repo\n",
        "\n",
        "# This command moves the 'resources' directory from 'temp_repo' to your current directory.\n",
        "!mv temp_repo/resources .\n",
        "!mv temp_repo/requirements.txt .\n",
        "\n",
        "# This deletes the 'temp_repo' directory, cleaning up the unwanted files.\n",
        "!rm -rf temp_repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojfRVcU2uPpr"
      },
      "source": [
        "### Install Python Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tpqa4wdIuPps"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5MkAESllPgm"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBlbUrB27QQs"
      },
      "source": [
        "### Install Redis Stack\n",
        "\n",
        "Later in this tutorial, Redis will be used to store, index, and query vector\n",
        "embeddings created from PDF document chunks. **We need to make sure we have a Redis\n",
        "instance available.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxx67XDRlPgm"
      },
      "source": [
        "#### Method 1: localized Redis Stack\n",
        "Use the shell script below to download, extract, and install [Redis Stack](https://redis.io/docs/getting-started/install-stack/) directly\n",
        "from the Redis package archive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKMKXPY2j8Gt"
      },
      "outputs": [],
      "source": [
        "%%sh\n",
        "curl -fsSL https://packages.redis.io/gpg | sudo gpg --dearmor -o /usr/share/keyrings/redis-archive-keyring.gpg\n",
        "echo \"deb [signed-by=/usr/share/keyrings/redis-archive-keyring.gpg] https://packages.redis.io/deb $(lsb_release -cs) main\" | sudo tee /etc/apt/sources.list.d/redis.list\n",
        "sudo apt-get update  > /dev/null 2>&1\n",
        "sudo apt-get install redis-stack-server  > /dev/null 2>&1\n",
        "redis-stack-server --daemonize yes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWwFz5G5lPgn"
      },
      "source": [
        "#### Method 2: Redis Cloud\n",
        "Instead of using the in-notebook, localized Redis Stack, you can quickly deploy a\n",
        "[FREE instance of Redis in the cloud](https://redis.com/try-free/). Or, if you have your\n",
        "own version of Redis Enterprise running, that works too!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gX_DsVDTlPgn"
      },
      "source": [
        "### Define the Redis Connection URL\n",
        "\n",
        "By default this notebook connects to the local instance of Redis Stack. **If you have your own Redis Enterprise instance** - replace REDIS_PASSWORD, REDIS_HOST and REDIS_PORT values with your own."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyPfCO3pkB7M"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Replace values below with your own if using Redis Cloud instance\n",
        "REDIS_HOST = os.getenv(\"REDIS_HOST\", \"localhost\")\n",
        "REDIS_PORT = os.getenv(\"REDIS_PORT\", \"6379\")\n",
        "REDIS_PASSWORD = os.getenv(\"REDIS_PASSWORD\", \"\")\n",
        "#REDIS_HOST=\"redis-18374.c253.us-central1-1.gce.cloud.redislabs.com\"\n",
        "#REDIS_PORT=18374\n",
        "#REDIS_PASSWORD=\"1TNxTEdYRDgIDKM2gDfasupCADXXXX\"\n",
        "\n",
        "# If SSL is enabled on the endpoint, use rediss:// as the URL prefix\n",
        "REDIS_URL = f\"redis://:{REDIS_PASSWORD}@{REDIS_HOST}:{REDIS_PORT}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOyDXMkClPgo"
      },
      "source": [
        "## Hello World Redis\n",
        "\n",
        "Now let's connect to the Redis db and get a basic feel for the most common\n",
        "commands and data structures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWWtZkVGlPgo"
      },
      "outputs": [],
      "source": [
        "import redis\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "from time import sleep\n",
        "\n",
        "# Connect with the Redis Python Client\n",
        "client = redis.Redis.from_url(REDIS_URL)\n",
        "\n",
        "client.ping()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9acMEohlPgo"
      },
      "outputs": [],
      "source": [
        "client.dbsize() # should be empty"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kABe5nolPgo"
      },
      "source": [
        "Redis, at it's core, is a simple key/value store. It supports a number of interesting\n",
        "and flexible data structures that can solve a variatey of business and operational\n",
        "problems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJ0UswSslPgo"
      },
      "source": [
        "### Strings\n",
        "\n",
        "The basic string data type can be accessed using set/get methods. You can also place a\n",
        "TTL policy (expiration) on any key in Redis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRHB1NgglPgp"
      },
      "outputs": [],
      "source": [
        "client.set(\"hello\", \"world\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTUia16dlPgp"
      },
      "outputs": [],
      "source": [
        "client.get(\"hello\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I90TlsKhlPgp"
      },
      "outputs": [],
      "source": [
        "client.delete(\"hello\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lijoufOdlPgp"
      },
      "outputs": [],
      "source": [
        "client.set(\"hello\", \"world\")\n",
        "client.expire(\"hello\", time=3)\n",
        "\n",
        "sleep(4)\n",
        "\n",
        "# should be EMPTY\n",
        "client.get(\"hello\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-07OwP2YlPgp"
      },
      "source": [
        "### Hashes\n",
        "Hashes are collections of key/value pairs that are grouped together. It gets\n",
        "serialized as a string in Redis, but can hold a variety of data in each field.\n",
        "\n",
        "You can think of a Hash as a one-level deep Python dictionary.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FoQS6v9lPgq"
      },
      "outputs": [],
      "source": [
        "obj = {\n",
        "    \"user\": \"john\",\n",
        "    \"age\": 45,\n",
        "    \"job\": \"dentist\",\n",
        "    \"bio\": \"long form text of john's bio\",\n",
        "    \"user_embedding\": np.array([0.3, 0.4, -0.8], dtype=np.float32).tobytes() # cast vectors to bytes string\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2dEFhRUlPgq"
      },
      "outputs": [],
      "source": [
        "client.hset(\"user:john\", mapping=obj)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7o9jvWHdlPgq"
      },
      "outputs": [],
      "source": [
        "client.hgetall(\"user:john\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIC0kjMKlPgq"
      },
      "outputs": [],
      "source": [
        "client.delete(\"user:john\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjtOwf6UlPgq"
      },
      "source": [
        "### JSON\n",
        "With the JSON capabilitie enabled, Redis can be a drop-in replacement for MongoDB\n",
        "or other slower document databases. You can store nested and structured JSON data\n",
        "directly in Redis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQViZiW4lPgq"
      },
      "outputs": [],
      "source": [
        "# set a JSON obj\n",
        "obj = {\n",
        "    \"user\": \"john\",\n",
        "    \"metadata\": {\n",
        "        \"age\": 45,\n",
        "        \"job\": \"dentist\",\n",
        "    },\n",
        "    \"user_embedding\": [0.3, 0.4, -0.8]\n",
        "}\n",
        "\n",
        "client.json().set(\"user:john\", \"$\", obj)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFBOXglUlPgr"
      },
      "outputs": [],
      "source": [
        "# get user JSON obj\n",
        "client.json().get(\"user:john\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oAY90h-IlPgr"
      },
      "outputs": [],
      "source": [
        "# grab array length for embedding field\n",
        "client.json().arrlen(\"user:john\", \"$.user_embedding\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNz3-8dUlPgr"
      },
      "outputs": [],
      "source": [
        "# grab obj keys\n",
        "client.json().objkeys(\"user:john\", \"$\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAbM4isblPgr"
      },
      "outputs": [],
      "source": [
        "# delete user JSON\n",
        "client.delete(\"user:john\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z78GyOT0lPgr"
      },
      "source": [
        "### Lists\n",
        "Lists store sequences of information... potentially list of messages in an LLM\n",
        "converstion flow, or really any list of items in a queue."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpCzMPNzlPgr"
      },
      "outputs": [],
      "source": [
        "# add items to a list\n",
        "client.rpush(\"messages:john\", *[\n",
        "    json.dumps({\"role\": \"user\", \"content\": \"Hello what can you do for me?\"}),\n",
        "    json.dumps({\"role\": \"assistant\", \"content\": \"Hi, I am a helpful virtual assistant.\"})\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cElm0GrLlPgs"
      },
      "outputs": [],
      "source": [
        "# list all items in the list using indices\n",
        "[json.loads(msg) for msg in client.lrange(\"messages:john\", 0, -1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1QvWNXElPgs"
      },
      "outputs": [],
      "source": [
        "# count items in the list\n",
        "client.llen(\"messages:john\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRhkFhdtlPgs"
      },
      "outputs": [],
      "source": [
        "# pop the first item from the list and push to another list\n",
        "client.rpoplpush(\"messages:john\", \"read_messages:john\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLkmGClFlPgs"
      },
      "outputs": [],
      "source": [
        "client.lrange(\"read_messages:john\", 0, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qljRgrslPgs"
      },
      "outputs": [],
      "source": [
        "# list cleanup\n",
        "client.delete(\"messages:john\", \"read_messages:john\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzDlzHvRlPgt"
      },
      "source": [
        "### Pipelines\n",
        "All Redis commands can be pipelined to gain some round trip latency improvements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6V1Xw6GlPgt"
      },
      "outputs": [],
      "source": [
        "with client.pipeline(transaction=False) as pipe:\n",
        "    for i in range(50):\n",
        "        pipe.json().set(f\"user:{i}\", \"$\", obj)\n",
        "    # execute batch\n",
        "    pipe.execute()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7Yh2Mk4lPgt"
      },
      "outputs": [],
      "source": [
        "client.dbsize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lpZ8iDoslPgt"
      },
      "outputs": [],
      "source": [
        "# clean up!\n",
        "client.flushall()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyjbc2t5lPgt"
      },
      "source": [
        "## Intro to Vector Search in Redis\n",
        "\n",
        "Now that we have the basics down, we will dive into the fundamentals of vector\n",
        "search in Redis using the base Python client."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVMewycguPps"
      },
      "source": [
        "### Dataset Preparation (PDF Documents)\n",
        "\n",
        "To best demonstrate Redis as a vector database layer, we will load a single\n",
        "financial (10k filings) doc and preprocess it using some helpers from LangChain:\n",
        "\n",
        "- `UnstructuredFileLoader` is not the only document loader type that LangChain provides. Docs: https://python.langchain.com/docs/integrations/document_loaders/unstructured_file\n",
        "- `RecursiveCharacterTextSplitter` is what we use to create smaller chunks of text from the doc. Docs: https://python.langchain.com/docs/modules/data_connection/document_transformers/text_splitters/recursive_text_splitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MetibQiuPpt"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import UnstructuredFileLoader\n",
        "\n",
        "# Load list of pdfs from a folder\n",
        "data_path = \"resources/\"\n",
        "docs = [os.path.join(data_path, file) for file in os.listdir(data_path)]\n",
        "\n",
        "print(\"Listing available documents ...\", docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0jstjQZlPgu"
      },
      "outputs": [],
      "source": [
        "# fetch the Nike PDF\n",
        "doc = [doc for doc in docs if \"nke\" in doc][0]\n",
        "\n",
        "# set up the file loader/extractor and text splitter to create chunks\n",
        "loader = UnstructuredFileLoader(doc, mode=\"single\", strategy=\"fast\")\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2500, chunk_overlap=0)\n",
        "\n",
        "# extract, load, and make chunks\n",
        "chunks = loader.load_and_split(text_splitter)\n",
        "\n",
        "print(\"Done preprocessing. Created\", len(chunks), \"chunks of the original pdf\", doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHBpJGlruPpu"
      },
      "outputs": [],
      "source": [
        "# Take a look at content from a chunk\n",
        "print(chunks[25].page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8X2VgYUuPpv"
      },
      "source": [
        "### Text embedding generation with SentenceTransformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LnNBNI4-PA3Y"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# load model - may take a minute or two to download the first time\n",
        "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-41dOyVpOgDI"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "# create embeddings\n",
        "chunk_embeddings = model.encode([chunk.page_content for chunk in chunks])\n",
        "len(chunk_embeddings) == len(chunks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A6PexJgVDGB"
      },
      "source": [
        "### Set up some helper functions\n",
        "\n",
        "Helper functions to encode the single query vector and display redis search results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9y0Xc4jVVCCI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "def encode_one(input):\n",
        "    return model.encode(input).astype(np.float32).tobytes()\n",
        "\n",
        "\n",
        "def table_view(res):\n",
        "    if res.total == 0:\n",
        "        print(\"No documents found.\")\n",
        "        return None\n",
        "\n",
        "    res_df = pd.DataFrame([t.__dict__ for t in res.docs ]).drop(columns=[\"payload\"])\n",
        "    return res_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylykfqxeuPpy"
      },
      "source": [
        "### Define a schema and create an index\n",
        "Below we connect to Redis and create an index for vector search that contains a single text field and vector field."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xufdXgR6uPpy"
      },
      "outputs": [],
      "source": [
        "from redis.commands.search.field import TagField, TextField, VectorField\n",
        "from redis.commands.search.indexDefinition import IndexDefinition, IndexType\n",
        "from redis.commands.search.query import Query\n",
        "\n",
        "\n",
        "index_name = \"redispy\"\n",
        "key_prefix = f\"doc:{index_name}\"\n",
        "\n",
        "\n",
        "def create_index(index_type: str = \"FLAT\"):       # Creates a FLAT index by default\n",
        "    try:\n",
        "        # check to see if index exists\n",
        "        client.ft(index_name).info()\n",
        "        print(\"Index already exists!\")\n",
        "    except:\n",
        "        # define schema\n",
        "        schema = (\n",
        "            TagField(\"doc_id\"),                    # Tag Field - synthetic ID\n",
        "            TextField(\"content\"),                  # Text Field\n",
        "            VectorField(\"chunk_vector\",            # Vector Field\n",
        "                index_type, {                      # Vector Index Type: FLAT or HNSW\n",
        "                    \"TYPE\": \"FLOAT32\",\n",
        "                    \"DIM\": 384,                    # Number of Vector Dimensions\n",
        "                    \"DISTANCE_METRIC\": \"COSINE\",   # Vector Search Distance Metric\n",
        "                }\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        # index Definition\n",
        "        definition = IndexDefinition(prefix=[key_prefix], index_type=IndexType.HASH)\n",
        "\n",
        "        # create Index\n",
        "        client.ft(index_name).create_index(fields=schema, definition=definition)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMMYwKXPuPpz"
      },
      "outputs": [],
      "source": [
        "# Create the index\n",
        "create_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmIoE7MZuPpz"
      },
      "outputs": [],
      "source": [
        "# Check the info related to the newly created index\n",
        "client.ft(index_name).info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qrj-jeGmBRTL"
      },
      "source": [
        "### Process and load data using Redis\n",
        "Below we use a Redis pipeline (not a transaction) to batch send writes to Redis. This method helps with throughput significantly. The batch_size param can be customized and benchmarked on your hardware and with your data. We typically recommend starting small (100-200) and increasing as needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHsODPikuPp1"
      },
      "outputs": [],
      "source": [
        "# load expects an iterable of dictionaries\n",
        "\n",
        "batch_size = 200\n",
        "\n",
        "with client.pipeline(transaction=False) as pipe:\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        data = {\n",
        "            'doc_id': f\"{i}\",\n",
        "            'content': chunk.page_content,\n",
        "            # For HASH -- must convert embeddings to bytes\n",
        "            'chunk_vector': np.array(chunk_embeddings[i]).astype(np.float32).tobytes()\n",
        "        }\n",
        "        pipe.hset(f\"{key_prefix}:{i}\", mapping=data)\n",
        "        # execute in \"mini batches\"\n",
        "        if i % batch_size == 0:\n",
        "            res = pipe.execute()\n",
        "\n",
        "    # cleanup final batch execution\n",
        "    res = pipe.execute()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pY9Ja6VduPp1"
      },
      "outputs": [],
      "source": [
        "# check the data size in Redis\n",
        "len(chunks) == client.dbsize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xa5zeoZ1uPp7"
      },
      "outputs": [],
      "source": [
        "client.hgetall(f\"{key_prefix}:0\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBMVO9RQuPp7"
      },
      "source": [
        "### Query the database\n",
        "Now we can use the Redis search index to perform vector similarity search operations.\n",
        "\n",
        "The code below takes a user input, converts to embeddings, and fetches the top 2 most semantically similar chunks from Redis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fp3I3jo4uPp8"
      },
      "outputs": [],
      "source": [
        "# Grab user input\n",
        "_input = \"Nike profit margins and company performance\"\n",
        "\n",
        "query = (\n",
        "    Query(\"*=>[KNN 2 @chunk_vector $vector as vector_distance]\")\n",
        "     .sort_by(\"vector_distance\")\n",
        "     .return_fields(\"content\", \"vector_distance\")\n",
        "     .paging(0, 2)\n",
        "     .dialect(2)\n",
        ")\n",
        "\n",
        "query_params = {\n",
        "    \"vector\": encode_one(_input)\n",
        "}\n",
        "\n",
        "res = client.ft(index_name).search(query, query_params)\n",
        "\n",
        "table_view(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VH2tTqYWCgpM"
      },
      "outputs": [],
      "source": [
        "# Example of sorting by a field other than vector_distance\n",
        "query = (\n",
        "    Query(\"*=>[KNN 4 @chunk_vector $vector as vector_distance]\")\n",
        "     .sort_by(\"doc_id\")\n",
        "     .return_fields(\"doc_id\", \"content\", \"vector_distance\")\n",
        "     .paging(0, 4)\n",
        "     .dialect(2)\n",
        ")\n",
        "\n",
        "query_params = {\n",
        "    \"vector\": encode_one(_input)\n",
        "}\n",
        "\n",
        "res = client.ft(index_name).search(query, query_params)\n",
        "\n",
        "table_view(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5SCvkAvuPp8"
      },
      "source": [
        "### Range Queries\n",
        "Range queries allow you to set a pre defined \"threshold\" for which we want to return documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTrphv_NuPp8"
      },
      "outputs": [],
      "source": [
        "query = (\n",
        "    Query(\"@chunk_vector:[VECTOR_RANGE $radius $vector]=>{$YIELD_DISTANCE_AS: vector_distance}\")\n",
        "     .sort_by(\"vector_distance\")\n",
        "     .return_fields(\"content\", \"vector_distance\")\n",
        "     .dialect(2)\n",
        ")\n",
        "\n",
        "# Find all vectors within 0.8 of the query vector\n",
        "query_params = {\n",
        "    \"radius\": 0.8,\n",
        "    \"vector\": encode_one(_input)\n",
        "}\n",
        "\n",
        "res = client.ft(index_name).search(query, query_params)\n",
        "table_view(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IELiO9e4uPp9"
      },
      "source": [
        "### Add filter statements\n",
        "Redis queries can contain both vector search and traditional filters (numeric, tags, text, geo) in one single command."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qkzGPmMnuPp-"
      },
      "outputs": [],
      "source": [
        "# filter for docs that contain \"profit\" in the content field and do KNN vector search\n",
        "query = (\n",
        "    Query(\"@content:profit=>[KNN 2 @chunk_vector $vector as vector_distance]\")\n",
        "     .sort_by(\"vector_distance\")\n",
        "     .return_fields(\"content\", \"vector_distance\")\n",
        "     .paging(0, 2)\n",
        "     .dialect(2)\n",
        ")\n",
        "\n",
        "query_params = {\n",
        "    \"vector\": encode_one(_input)\n",
        "}\n",
        "\n",
        "res = client.ft(index_name).search(query, query_params)\n",
        "table_view(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XpL7r3tquPp-"
      },
      "outputs": [],
      "source": [
        "# lets clean up our index\n",
        "client.ft(index_name).dropindex(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeJA5u14uPp-"
      },
      "source": [
        "### What about JSON Support?\n",
        "\n",
        "Redis also allows you to store data in JSON objects. The JSON fields can contain metadata and vectors. Below is a simple example of indexing JSON data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-V_gPbmguPp-"
      },
      "outputs": [],
      "source": [
        "# schema\n",
        "schema = (\n",
        "    TextField(\"$.content\",                     # Text Field (JSON path)\n",
        "        as_name=\"content\"                      # Text Field Alias -- required for JSON\n",
        "    ),\n",
        "    VectorField(\"$.chunk_vector\",              # Vector Field (JSON path)\n",
        "        \"FLAT\", {                              # Vector Index Type: FLAT or HNSW\n",
        "            \"TYPE\": \"FLOAT32\",\n",
        "            \"DIM\": 384,                        # Number of Vector Dimensions\n",
        "            \"DISTANCE_METRIC\": \"COSINE\",       # Vector Search Distance Metric\n",
        "        },\n",
        "        as_name=\"chunk_vector\"                 # Vector Field Alias -- required for JSON\n",
        "    ),\n",
        ")\n",
        "\n",
        "# index Definition\n",
        "definition = IndexDefinition(prefix=[key_prefix], index_type=IndexType.JSON) # select JSON here\n",
        "\n",
        "# create Index\n",
        "client.ft(index_name).create_index(fields=schema, definition=definition)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rh7NKirOuPp_"
      },
      "outputs": [],
      "source": [
        "client.ft(index_name).info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UawMtBgSuPp_"
      },
      "outputs": [],
      "source": [
        "# Write JSON data to the index\n",
        "\n",
        "batch_size = 200\n",
        "\n",
        "with client.pipeline(transaction=False) as pipe:\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        redis_key = f\"{key_prefix}:{i}\"\n",
        "        data = {\n",
        "            'content': chunk.page_content,\n",
        "            'chunk_vector': chunk_embeddings[i].tolist() # notice that we don't need to convert JSON embeddings to bytes\n",
        "        }\n",
        "        #print(data)\n",
        "        pipe.json().set(redis_key, \"$\", data)\n",
        "        # mini batch\n",
        "        if i % batch_size == 0:\n",
        "            res = pipe.execute()\n",
        "\n",
        "    res = pipe.execute() # make sure to use mini batches if working with larger datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aoJljsrAuPp_"
      },
      "outputs": [],
      "source": [
        "# Fetch the JSON doc\n",
        "client.json().get(f\"{key_prefix}:0\", \"$\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5yxhMciuPp_"
      },
      "outputs": [],
      "source": [
        "# And now you can perform the same kinds of queries\n",
        "query = (\n",
        "    Query(\"@content:profit=>[KNN 2 @chunk_vector $vector as vector_distance]\")\n",
        "     .sort_by(\"vector_distance\")\n",
        "     .return_fields(\"content\", \"vector_distance\")\n",
        "     .paging(0, 2)\n",
        "     .dialect(2)\n",
        ")\n",
        "\n",
        "query_params = {\n",
        "    \"vector\": encode_one(_input)\n",
        "\n",
        "}\n",
        "res = client.ft(index_name).search(query, query_params)\n",
        "\n",
        "table_view(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QKo9u3euPqA"
      },
      "source": [
        "## Cleanup\n",
        "Clean up the index and data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgACLAd0uPqA"
      },
      "outputs": [],
      "source": [
        "client.ft(index_name).dropindex(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRLKYfhguPqA"
      },
      "source": [
        "## What's Next?\n",
        "\n",
        "Now that you have the basics down with the baseline Redis Python client:\n",
        "\n",
        "| Notebook | Description | Documentation |\n",
        "|----------|-------------|---------------|\n",
        "| [**redisvl-02**](https://colab.research.google.com/github/redis-developer/financial-vss/blob/main/redisvl-02.ipynb) | Dive deeper using a dedicated VSS client library to build a RAG application from scratch including some advanced techniques using an OpenAI LLM. | [View Docs](https://redisvl.com) |\n",
        "| [**langchain-03**](https://colab.research.google.com/github/redis-developer/financial-vss/blob/main/langchain-03.ipynb) | Wrap up with an integrated approach via LangChain and see how to build complex LLM chains. | [View Docs](https://python.langchain.com/docs/get_started/introduction) |\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}